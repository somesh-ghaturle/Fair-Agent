# DeepSeek Coder Configuration for Continue.dev
# https://docs.continue.dev/reference

name: DeepSeek Config
version: 1.0.0
schema: v1

# Define which models can be used
# https://docs.continue.dev/customization/models
models:
  - name: DeepSeek Coder
    provider: openai
    model: deepseek-coder
    apiKey: sk-9d8400ee131a4eb99775fe0ccb9f31bf
    apiBase: https://api.deepseek.com/v1

  - name: DeepSeek R1 Reasoner
    provider: openai
    model: deepseek-reasoner
    apiKey: sk-9d8400ee131a4eb99775fe0ccb9f31bf
    apiBase: https://api.deepseek.com/v1

  # Your local Ollama model (optional)
  - name: Llama 3.2 Local
    provider: ollama
    model: llama3.2:latest
    apiBase: http://localhost:11435

# MCP Servers that Continue can access (optional)
# https://docs.continue.dev/customization/mcp-tools
mcpServers: []
