# FAIR-Agent: Trustworthy AI for High-Stakes Domains

**Team:** Somesh Ghaturle, Priyank Mistry  
**Institution:** Pace University | **Date:** October 26, 2025  

---

## üéØ Project Overview

FAIR-Agent is the **world's first LLM with quantifiable trustworthiness**, designed to revolutionize AI reliability through evidence-based responses and transparent reasoning. Unlike existing chatbots that operate as "black boxes," FAIR-Agent provides measurable trustworthiness through our revolutionary **FAIR metrics framework**.

**FAIR Acronym:**
- **F**aithful: Evidence-grounded responses with 100% source citations
- **A**daptable: Domain-specialized expertise (Finance & Medical)
- **I**nterpretable: Transparent step-by-step reasoning
- **R**isk-Aware: Comprehensive safety protocols and disclaimers

### Key Differentiators
| Feature | FAIR-Agent | Standard LLMs (GPT-4, etc.) |
|---------|-----------|-----------------------------|
| **Evidence** | 63 Curated Sources (SEC, CDC, etc.) | Unknown training data |
| **Citations** | 100% Citation Rate | < 5% Citation Rate |
| **Transparency** | Visible Chain-of-Thought | Black Box |
| **Metrics** | Real-time FAIR Scores | No Trust Metrics |
| **Privacy** | 100% Local (Ollama/Llama 3.2) | Cloud-based |
| **Strictness** | **No Evidence = No Answer** | Hallucinates answers |

---

## üèóÔ∏è System Architecture

The system operates on a comprehensive pipeline designed to ensure accuracy, safety, and observability.

> **üìò New:** Read our detailed [Memory & Learning Architecture](docs/MEMORY_AND_LEARNING.md) documentation to understand how FAIR-Agent learns without fine-tuning.

### Complete System Architecture

```mermaid
%%{init: {'theme': 'base', 'themeVariables': { 'primaryColor': '#ffcc00', 'edgeLabelBackground':'#ffffff', 'tertiaryColor': '#fff', 'fontSize': '20px'}, 'flowchart': {'nodeSpacing': 50, 'rankSpacing': 50, 'curve': 'basis'}}}%%
flowchart TD
    classDef user fill:#f9f,stroke:#333,stroke-width:4px,font-size:24px,font-weight:bold;
    classDef frontend fill:#bbf,stroke:#333,stroke-width:3px,font-size:20px;
    classDef core fill:#bfb,stroke:#333,stroke-width:3px,font-size:20px;
    classDef rag fill:#fbb,stroke:#333,stroke-width:3px,font-size:20px;
    classDef ai fill:#ddf,stroke:#333,stroke-width:3px,font-size:20px;
    classDef obs fill:#ddd,stroke:#333,stroke-width:3px,font-size:20px;

    subgraph User_Layer [User Interaction Layer]
        User((User)):::user
        Browser["Web Browser / UI<br/>(HTML/JS/CSS)"]:::frontend
    end

    subgraph Web_Layer [Web Application Layer]
        Django["Django Server<br/>(WSGI/ASGI)"]:::frontend
        Views["View Logic<br/>(views.py)"]:::frontend
        API["REST API Endpoints<br/>(/api/query)"]:::frontend
        Session["Session Manager<br/>(DB/Cache)"]:::frontend
    end

    subgraph Core_Layer [Core Orchestration Layer]
        Orchestrator["Orchestrator System<br/>(orchestrator.py)"]:::core
        SpellCheck["Spell & Query Fixer<br/>(spell_checker.py)"]:::core
        Classifier["Domain Classifier<br/>(Regex/Keyword)"]:::core
        Router{Router}:::core
        Aggregator["Response Aggregator<br/>(JSON Builder)"]:::core
        Safety["Safety & Ethics Filter<br/>(Pattern Matcher)"]:::core
    end

    subgraph Agent_Layer [Domain Agents]
        FinAgent["Finance Agent<br/>(finance_agent.py)"]:::core
        MedAgent["Medical Agent<br/>(medical_agent.py)"]:::core
        CrossAgent["Cross-Domain Logic<br/>(Synthesis)"]:::core
        Reasoning["Reasoning Engine<br/>(cot_system.py)"]:::core
    end

    subgraph RAG_Layer ["RAG & Knowledge Layer"]
        QueryEnc["Query Encoder<br/>(all-MiniLM-L6-v2)"]:::rag
        VectorDB[("ChromaDB Vector Store<br/>(Persistent)")]:::rag
        KnowledgeGraph[("Knowledge Graph<br/>(NetworkX)")]:::rag
        DocStore[("Evidence Sources<br/>YAML/JSON")]:::rag
        Internet["Internet Search<br/>(internet_rag.py)"]:::rag
        HybridSearch["Hybrid Search Engine<br/>(Semantic + Keyword)"]:::rag
        ReRanker["Cross-Encoder Re-ranker<br/>(ms-marco-MiniLM)"]:::rag
        ContextWindow["Context Window Manager<br/>(Token Limiter)"]:::rag
    end

    subgraph Inference_Layer [Inference Layer]
        Ollama["Ollama API Client<br/>(HTTP/JSON)"]:::ai
        LlamaService["Ollama Service<br/>(Localhost:11434)"]:::ai
        Model[["Llama 3.2 Model<br/>(GGUF Quantized)"]]:::ai
    end

    subgraph Obs_Layer ["Observability & Evaluation"]
        Telemetry["Telemetry Manager<br/>(telemetry.py)"]:::obs
        Tracer["Trace Storage<br/>(logs/telemetry + DB)"]:::obs
        Metrics["Metrics Store<br/>(Latency/Tokens)"]:::obs
        Evaluator["Offline Evaluator<br/>(evaluate.py)"]:::obs
        Benchmarks[("Benchmark Datasets<br/>FinQA/MedMCQA")]:::obs
        
        %% Metrics Details
        M_Faith["Faithfulness<br/>(faithfulness.py)"]:::obs
        M_Safe["Safety<br/>(safety.py)"]:::obs
        M_Adapt["Adaptability<br/>(adaptability.py)"]:::obs
        M_Interp["Interpretability<br/>(interpretability.py)"]:::obs
    end

    %% Flows
    User -->|1. Submit Query| Browser
    Browser -->|2. HTTP POST| Django
    Django -->|3. Route Request| Views
    Views -->|4. API Call| API
    API -->|5. Process| Orchestrator

    %% Orchestration Flow
    Orchestrator -->|Pre-process| SpellCheck
    SpellCheck -->|6. Classify| Classifier
    Classifier -->|Domain Tag| Router
    Router -->|Finance| FinAgent
    Router -->|Medical| MedAgent
    Router -->|Both| CrossAgent

    %% RAG Flow
    FinAgent & MedAgent -->|7. Retrieve Context| HybridSearch
    HybridSearch -->|Encode Query| QueryEnc
    QueryEnc -->|Vector Search| VectorDB
    HybridSearch -->|Graph Search| KnowledgeGraph
    HybridSearch -->|Keyword Search| DocStore
    FinAgent & MedAgent -->|Web Search| Internet
    VectorDB & KnowledgeGraph & DocStore & Internet -->|Candidates| ReRanker
    ReRanker -->|Top K Evidence| ContextWindow
    ContextWindow -->|Formatted Context| Reasoning

    %% Inference Flow
    Reasoning -->|8. Construct CoT| FinAgent & MedAgent
    FinAgent & MedAgent -->|9. Send Prompt| Ollama
    Ollama -->|Generate| LlamaService
    LlamaService -->|Inference| Model
    Model -->|Tokens| LlamaService
    LlamaService -->|Response Stream| Ollama
    Ollama -->|Text| FinAgent & MedAgent

    %% Response Flow
    FinAgent & MedAgent -->|10. Raw Response| Safety
    Safety -->|Validated Response| Aggregator
    Aggregator -->|Final Output| Orchestrator
    Orchestrator -->|JSON Response| API
    API -->|Return Data| Views
    Views -->|Render Template| Browser
    Browser -->|Display| User

    %% Observability Flow
    Orchestrator -.->|Start Trace| Telemetry
    FinAgent & MedAgent -.->|Span| Telemetry
    Ollama -.->|Latency/Tokens| Telemetry
    Telemetry -->|Store| Tracer & Metrics
    Evaluator -.->|Read| Metrics
    Evaluator -.->|Compare| Benchmarks
    
    %% Metrics Calculation Flow
    Evaluator -.->|Calculate| M_Faith
    Evaluator -.->|Calculate| M_Safe
    Evaluator -.->|Calculate| M_Adapt
    Evaluator -.->|Calculate| M_Interp
```

### Workflow Steps
1.  **User Query**: Received via Django web interface.
2.  **Domain Classification**: Orchestrator routes to Finance, Medical, or Cross-Domain agent.
3.  **Advanced RAG & Memory**: 
    *   **Vector Memory**: **ChromaDB** stores embeddings and execution traces for long-term recall.
    *   **Knowledge Graph**: **NetworkX** graph learns entities and relationships from interactions.
    *   **Hybrid Search**: Combines Semantic (Vector), Graph, and Keyword search.
    *   **Re-ranking**: Uses Cross-Encoders to select the best evidence.
4.  **AI Processing**: Local Llama 3.3/3.2 model generates raw response.
5.  **Enhancement Pipeline**: Adds Chain-of-Thought reasoning and safety checks.
6.  **Standardization**: Formats response into 7 distinct sections.
7.  **FAIR Evaluation**: Calculates real-time scores (F, A, I, R).
8.  **Observability**: Distributed tracing tracks execution flow and performance.
9.  **Response Delivery**: Streamed to user with full transparency.

### Detailed Pipeline Breakdown

#### Stage 1: Query Reception & Validation
```mermaid
flowchart LR
    A[üë§ User Input] --> B[üåê Django Web Interface]
    B --> C[‚úÖ Input Validation]
    C --> D[üìù Session Management]
    D --> E[üìä Query Logging]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#f1f8e9
```

#### Stage 2: Domain Classification & Intelligence Routing
```mermaid
flowchart LR
    A[üìù Query Text] --> B[üîç NLP Analysis]
    B --> C[üìä Domain Confidence Scoring]
    C --> D{üéØ Agent Selection}
    
    D -->|Finance 94.2%| E[üí∞ Finance Agent]
    D -->|Medical 91.8%| F[üè• Medical Agent]
    D -->|Cross-Domain 87.3%| G[üîÑ Multi-Agent]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#e8f4f8
    style F fill:#f0f8ff
    style G fill:#fff8e1
```

#### Stage 3: Specialized Agent Processing
```mermaid
flowchart LR
    A[üéØ Routed Query] --> B{ü§ñ Domain Agent}
    
    B -->|Finance Domain| C[üí∞ Finance Agent]
    B -->|Medical Domain| D[üè• Medical Agent]
    B -->|Cross-Domain| E[üîÑ Both Agents]
    
    C --> F[üìä Financial Analysis]
    D --> G[‚öïÔ∏è Medical Analysis]
    E --> H[üîÑ Multi-Domain Synthesis]
    
    F --> I[üíº Initial Finance Response]
    G --> J[ü©∫ Initial Medical Response]
    H --> K[üåê Cross-Domain Response]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f4f8
    style D fill:#f0f8ff
    style E fill:#fff8e1
    style F fill:#f3e5f5
    style G fill:#e8f5e8
    style H fill:#ffeaa7
    style I fill:#dda0dd
    style J fill:#98fb98
    style K fill:#f0e68c
```

#### Stage 4: Advanced Evidence Retrieval (New!)
```mermaid
flowchart TD
    A[üéØ Agent Query] --> B[üîÑ Query Expansion]
    B --> C{üîç Hybrid Search}
    
    C -->|Semantic Search| D[üß† ChromaDB Vector Store]
    C -->|Graph Search| K[üï∏Ô∏è Knowledge Graph]
    C -->|Keyword Search| E[üìù BM25 / Keywords]
    
    D --> F[üìë Candidate Pool]
    K --> F
    E --> F
    
    F --> G[‚öñÔ∏è Cross-Encoder Re-ranking]
    G --> H{‚úÖ Evidence Found?}
    
    H -->|Yes| I[üìö Top-3 Verified Sources]
    H -->|No| J[üö´ Strict Refusal Protocol]
    
    J --> K_Log[üìù Log Missing Evidence]
    J --> L[‚ùå 'No Evidence' Response]
    
    style A fill:#e3f2fd
    style B fill:#e1bee7
    style C fill:#fff3e0
    style D fill:#e8f4f8
    style K fill:#e8f4f8
    style E fill:#f0f8ff
    style F fill:#f5f5dc
    style G fill:#ffcc80
    style H fill:#fff9c4
    style I fill:#c8e6c9
    style J fill:#ffcdd2
    style K_Log fill:#cfd8dc
    style L fill:#ffab91
```

#### Stage 5: AI Model Processing
```mermaid
flowchart LR
    A[üìö Evidence + Query] --> B[üîÑ Context Assembly]
    B --> C[üß† Ollama LLM<br/>llama3.2:latest]
    C --> D[üí≠ Context-Aware Response]
    D --> E{üéØ Domain Expertise}
    
    E -->|Finance| F[üí∞ Financial Analysis]
    E -->|Medical| G[‚öïÔ∏è Medical Analysis]
    E -->|Cross-Domain| H[üîÑ Multi-Domain]
    
    F --> I[üìä Domain Response]
    G --> J[ü©∫ Clinical Response]
    H --> K[üåê Synthesized Response]
    
    style A fill:#e3f2fd
    style B fill:#f3e5f5
    style C fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#fff8e1
    style F fill:#e8f4f8
    style G fill:#f0f8ff
    style H fill:#ffeaa7
    style I fill:#dda0dd
    style J fill:#98fb98
    style K fill:#f0e68c
```

#### Stage 6: Enhancement Pipeline
```mermaid
flowchart LR
    A[üó£Ô∏è Raw Response] --> B[üîó Chain-of-Thought]
    B --> C[üõ°Ô∏è Safety Checks]
    C --> D[‚ö†Ô∏è Disclaimer Addition]
    D --> E[üìù Structure & Format]
    
    B --> F[üí≠ Reasoning Steps]
    C --> G[üö® Risk Assessment]
    D --> H[üìã Compliance Checks]
    E --> I[‚ú® Enhanced Response]
    
    F --> I
    G --> I
    H --> I
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#ffebee
    style D fill:#fff8e1
    style E fill:#f3e5f5
    style F fill:#e8f5e8
    style G fill:#ffeaa7
    style H fill:#e0ffff
    style I fill:#f0e68c
```

#### Stage 7: FAIR Evaluation & Scoring
```mermaid
flowchart TD
    A[üìÑ Enhanced Response + Evidence] --> B[üîç Faithfulness Evaluation]
    A --> C[üéØ Adaptability Evaluation]
    A --> D[üîç Interpretability Evaluation]
    A --> E[‚ö†Ô∏è Risk Assessment]
    
    B --> F[üìä F-Score: 0-100]
    C --> G[üìà A-Score: 0-100]
    D --> H[üí° I-Score: 0-100]
    E --> I[üö® R-Score: 0-100]
    
    F --> J[‚ö° FAIR Composite Score]
    G --> J
    H --> J
    I --> J
    
    J --> K[üìã Quality Report]
    K --> L[‚úÖ Final Response Package]
    
    B --> M[Evidence Grounding %]
    C --> N[Domain Expertise %]
    D --> O[Reasoning Transparency %]
    E --> P[Safety Disclaimer %]
    
    style A fill:#e3f2fd
    style B fill:#ffebee
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#ffeaa7
    style F fill:#ffcdd2
    style G fill:#c8e6c9
    style H fill:#ffe0b2
    style I fill:#ffecb3
    style J fill:#f0e68c
    style K fill:#e1bee7
    style L fill:#dcedc8
```

#### Stage 8: Response Delivery & Analytics
```mermaid
flowchart LR
    A[üìä FAIR Score + Response] --> B[üìù Format Response]
    B --> C[üìà Record Analytics]
    C --> D[üöÄ Deliver to User]
    D --> E[üíæ Store Session Data]
    
    B --> F[üé® HTML Formatting]
    C --> G[üìä Performance Metrics]
    D --> H[üåê WebSocket Delivery]
    E --> I[üóÑÔ∏è Database Storage]
    
    F --> J[üë§ User Interface]
    G --> K[üìã Dashboard Updates]
    H --> J
    I --> L[üìö Query History]
    
    J --> M[üéØ Real-time Response]
    K --> N[üìä Analytics Dashboard]
    L --> O[üîç Future Improvements]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#e8f5e8
    style D fill:#ffebee
    style E fill:#f3e5f5
    style F fill:#ffe0b2
    style G fill:#c8e6c9
    style H fill:#ffcdd2
    style I fill:#e1bee7
    style J fill:#f0e68c
    style K fill:#b3e5fc
    style L fill:#dcedc8
    style M fill:#81c784
    style N fill:#64b5f6
    style O fill:#ffb74d
```

### System Component Architecture

```mermaid
graph TB
    subgraph "üåê Frontend Layer"
        UI[Web Interface<br/>Django Templates]
        API[REST API<br/>WebSocket Support]
        DASH[Real-time Dashboard<br/>FAIR Metrics Display]
    end
    
    subgraph "üéØ Orchestration Layer"
        ORCH[Main Orchestrator<br/>Query Router & Manager]
        CACHE[Response Cache<br/>Performance Optimization]
        SESSION[Session Management<br/>User Context]
    end
    
    subgraph "ü§ñ Multi-Agent System"
        FA[Finance Agent<br/>Financial Expertise]
        MA[Medical Agent<br/>Healthcare Knowledge]
        CROSS[Cross-Domain<br/>Multi-Agent Synthesis]
    end
    
    subgraph "üß† Enhancement Pipeline"
        RAG[RAG System<br/>63 Evidence Sources]
        COT[Chain-of-Thought<br/>Reasoning Engine]
        SAFETY[Safety System<br/>Disclaimers & Compliance]
    end
    
    subgraph "üìè FAIR Evaluation Engine"
        FAITH[Faithfulness<br/>Evidence Grounding]
        ADAPT[Adaptability<br/>Domain Expertise]
        INTERP[Interpretability<br/>Reasoning Transparency]
        RISK[Risk Awareness<br/>Safety Compliance]
    end
    
    subgraph "üîß Infrastructure Layer"
        OLLAMA[Ollama LLM Server<br/>llama3.2:latest]
        DB[(SQLite Database<br/>Query History & Analytics)]
        EMBED[Sentence Transformers<br/>Semantic Search]
        LOGS[(Logging System<br/>Performance Monitoring)]
    end
```

### üìä New Features (Dec 2025)
- **System Dashboard**: Real-time telemetry visualization including trace execution, latency metrics, and error tracking.
- **Publication Page**: Integrated research abstract viewer for SARD 2025.
- **Enhanced UI**: Improved architecture diagrams and responsive design.
- **Strict Evidence Protocol**: "No Evidence = No Answer" policy to eliminate hallucinations.

### Tech Stack
*   **Backend**: Python 3.13, Django 4.2.7
*   **AI Engine**: Ollama (Llama 3.2:latest), SentenceTransformers (all-MiniLM-L6-v2)
*   **Database**: SQLite (History), FAISS (Vector Search)
*   **Frontend**: HTML5, Bootstrap 5, WebSockets

---

## üöÄ Core Features

### 1. Response Standardization
Every response follows a strict 7-section format to ensure consistency and readability.

| Section | Description |
|---------|-------------|
| **1. Direct Answer** | Concise summary of the answer. |
| **2. Confidence Score** | AI's confidence (0.0 - 1.0) based on evidence strength. |
| **3. Key Evidence** | Bullet points of facts retrieved from trusted sources. |
| **4. Source Citations** | Links to the 63 curated sources (e.g., `[1] Mayo Clinic`). |
| **5. Reasoning Process** | Step-by-step logic used to reach the conclusion. |
| **6. Strategic Analysis** | Domain-specific insights (Medical/Financial implications). |
| **7. Safety Disclaimer** | Mandatory domain-specific warnings. |

### 2. Dynamic Baseline Calculation
Unlike competitors using hardcoded assumptions, FAIR-Agent calculates **real baseline scores** through scientific LLM performance testing.

*   **Methodology**: We test the "Vanilla" Llama 3.2 model against our test set weekly.
*   **Current Baselines (Oct 2025)**:
    *   Faithfulness: 53.9%
    *   Adaptability: 76.1%
    *   Interpretability: 42.4%
    *   Risk Awareness: 60.4%
*   **Impact**: Allows us to measure *true* system improvement (e.g., +17.4% Faithfulness).

### 3. FAIR Metrics Framework
We quantify trust using four distinct metrics, implemented in `src/evaluation/`:

*   **Faithfulness (F)**: Measures how accurately the generated response reflects the retrieved evidence without hallucination.
    *   *Method*: Token Overlap & Semantic Similarity (BERTScore).
    *   *Target*: > 0.85 Cosine Similarity.
    *   *Implementation*: `src/evaluation/faithfulness.py`
*   **Adaptability (A)**: Evaluates the system's ability to switch contexts (Finance <-> Medical) and handle cross-domain queries.
    *   *Method*: Domain Classification Accuracy on mixed-domain synthetic queries.
    *   *Implementation*: `src/evaluation/adaptability.py`
*   **Interpretability (I)**: Assesses transparency via evidence/citations and the captured execution-step workflow trace.
    *   *Method*: Citation Count & Execution-Step Trace Coverage.
    *   *Requirement*: Include Evidence Sources and an "Execution Steps (Actual Workflow)" trace.
    *   *Implementation*: `src/evaluation/interpretability.py`
*   **Risk Awareness (R)**: Ensures responses do not contain harmful advice, bias, or toxic content.
    *   *Method*: Keyword Filtering & Sentiment Analysis (Medical Disclaimer Presence, Financial Advice Warning).
    *   *Implementation*: `src/evaluation/safety.py`

### 4. Evidence Methodology
Our RAG system uses a curated database of **63 high-reliability sources**:
*   **Medical (14)**: Mayo Clinic, CDC, NIH, etc. (Reliability: 95-98%)
*   **Financial (21)**: SEC, Federal Reserve, CFPB, etc. (Reliability: 85-94%)
*   **Datasets (18)**: FinQA, MedMCQA, PubMedQA.

---

## üíª Installation & Usage

### Prerequisites
*   Python 3.10+
*   [Ollama](https://ollama.ai/) installed and running.
*   `llama3.2` model pulled (`ollama pull llama3.2`).

### Setup
1.  **Clone the repository**:
    ```bash
    git clone https://github.com/somesh-ghaturle/Fair-Agent.git
    cd Fair-Agent
    ```

2.  **Install dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Start Ollama**:
    ```bash
    ollama serve
    ```

4.  **Run the Server**:
    ```bash
    python start_server.py
    ```
    Access the web interface at `http://127.0.0.1:8000`.

### Demo Scripts
*   **Run Baseline Evaluation**: `python scripts/run_baseline_evaluation.py`
*   **Compare Baselines**: `python scripts/baseline_comparison_demo.py`
*   **Test Standardization**: `python src/agents/test_standardization.py`

---

## üìÇ Project Structure

```
Fair-Agent/
‚îú‚îÄ‚îÄ config/                 # System configurations (YAML)
‚îú‚îÄ‚îÄ data/                   # Datasets and Embeddings cache
‚îú‚îÄ‚îÄ results/                # Evaluation logs and baseline scores
‚îú‚îÄ‚îÄ scripts/                # Utility and demo scripts
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/             # Finance, Medical, and Orchestrator agents
‚îÇ   ‚îú‚îÄ‚îÄ core/               # System core and model management
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/         # FAIR metrics implementation
‚îÇ   ‚îú‚îÄ‚îÄ evidence/           # RAG system and retrieval logic
‚îÇ   ‚îú‚îÄ‚îÄ reasoning/          # Chain-of-Thought logic
‚îÇ   ‚îú‚îÄ‚îÄ safety/             # Disclaimer and safety systems
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Logger and clients
‚îú‚îÄ‚îÄ webapp/                 # Django web application
‚îú‚îÄ‚îÄ main.py                 # CLI entry point
‚îú‚îÄ‚îÄ start_server.py         # Server launcher
‚îî‚îÄ‚îÄ README.md               # This file
```

---

## üìä Performance Benchmarks

**Comparison against Calculated Baselines (Oct 2025):**

| Metric | Baseline | FAIR-Agent | Improvement |
|--------|----------|------------|-------------|
| **Faithfulness** | 53.9% | **63.3%** | +17.4% |
| **Adaptability** | 76.1% | **80.2%** | +5.4% |
| **Interpretability** | 42.4% | **37.6%** | -11.3% (Focus area) |
| **Risk Awareness** | 60.4% | **66.6%** | +10.3% |
| **Overall Score** | 58.2% | **62.0%** | +6.5% |

*Note: Interpretability is lower because the baseline "Vanilla" model often gives short, simple answers which score high on clarity, whereas FAIR-Agent provides complex, structured reasoning which is harder to score but more transparent.*

---

## üîÆ Future Roadmap

1.  **Short-term (3-6 months)**:
    *   Optimize response time to < 1.5s.
    *   Expand evidence base to 100+ sources.
    *   Add multi-modal support (images/charts).
2.  **Mid-term (6-12 months)**:
    *   Add Legal and Education domain agents.
    *   Implement user personalization.
    *   Develop mobile application.
3.  **Long-term (12+ months)**:
    *   EU AI Act certification.
    *   Federated learning for privacy-preserving updates.

---

## üìÑ License

This project is licensed under the MIT License - see the LICENSE file for details.
